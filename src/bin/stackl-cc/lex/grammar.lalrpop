use std::cell::RefCell;
use std::rc::Rc;
use std::io::{Read, BufReader};
use std::fs;
use std::path::PathBuf;

use crate::tok;
use crate::diag::lex as diag;
use lalrpop_util as lalr;
use crate::lex::PPTokenStack;
use crate::lex::lexer::Lexer;

grammar<'a>(
	file_map: &mut bimap::BiHashMap<usize, PathBuf>,
	stack_ref: &'a Rc<RefCell<PPTokenStack>>
);

pub Tokens: Vec<tok::Token> = Group => <>;

Group: Vec<tok::Token> = {
	GroupPart => <>,
	<mut g: Group> <mut gp: GroupPart> => {
		g.append(&mut gp);
		g
	},
}

GroupPart: Vec<tok::Token> = {
	// IfSection => <>,
	ControlLine => <>,
	TextLine => <>,
	// "#" NonDirective => <>
};

ControlLine: Vec<tok::Token> = {
	// TODO: make this fallible
	"#" Include <header:HEADER_NAME> "\n" => {
		let origin_path = file_map.get_by_left(&header.file_key).unwrap();
		let header_name = PathBuf::from(header.kind.to_name());
		let full_path = origin_path.parent().unwrap().join(header_name);
		let mut stack = stack_ref.borrow_mut();
		let mut file = fs::File::open(&full_path).unwrap();
		
		let mut reader = BufReader::new(file);
		let mut buf = String::new();
		reader.read_to_string(&mut buf).unwrap();
		drop(reader);

		let file_key = if let Some(file_key) = file_map.get_by_right(&full_path) {
			*file_key
		} else {
			let file_key = file_map.len();
			file_map.insert(file_key, full_path);
			file_key
		};

		let lexer = Lexer::new(buf, file_key);
		stack.push_lexer(lexer);
		vec![]
	},
};

TextLine: Vec<tok::Token> = {
	"\n" => vec![],
	<nh:NonHash> <mut tokens:PreprocessingToken*> "\n" => {
		let mut result = vec![nh];
		result.append(&mut tokens);
		result
	},
};

PreprocessingToken: tok::Token = {
	HEADER_NAME => {
		todo!("header-name");
	},
	IDENT => {
		let file_key = <>.file_key;
		tok::Token{
			kind: <>.unwrap_ident().into(),
			file_key,
		}
	},
	PP_NUMBER => {
		let file_key = <>.file_key;
		let pp_num = <>.unwrap_pp_number();
		tok::Token {
			kind: tok::TokenKind::try_from(pp_num).unwrap(),
			file_key,
		}
	},
	CHAR_CONST => {
		let file_key = <>.file_key;
		tok::Token {
			kind: tok::TokenKind::Constant(tok::Constant::CharConst(<>.unwrap_char_const())),
			file_key,
		}
	},
	STRING_LITERAL => {
		let file_key = <>.file_key;
		tok::Token {
			kind: <>.unwrap_string_literal().into(),
			file_key,
		}
	},
	PUNCT => {
		let file_key = <>.file_key;
		tok::Token {
			kind: tok::TokenKind::Punct(<>.unwrap_punct()),
			file_key,
		}
	}
};


Include: tok::Ident = <lo:@L> <ident:IDENT> <hi:@R> =>? {
	if ident.unwrap_ident().0 == "include".to_string() {
		Ok(tok::Ident("include".to_string()))
	} else {
		Err(lalr::ParseError::User {
			error: diag::Error{
				kind: diag::ErrorKind::InvalidToken,
				loc: (lo, hi)
			}
		})
	}
};

NonHash: tok::Token = {
	IDENT => {
		let file_key = <>.file_key;
		tok::Token{
			kind: tok::TokenKind::Ident(<>.unwrap_ident()),
			file_key,
		}
	},
	STRING_LITERAL => {
		let file_key = <>.file_key;
		tok::Token {
			kind: tok::TokenKind::StringLiteral(<>.unwrap_string_literal()),
			file_key,
		}
	},
	NON_HASH_PUNCT => {
		let file_key = <>.file_key;
		tok::Token {
			kind: tok::TokenKind::Punct(<>.unwrap_punct()),
			file_key,
		}
	},
};

PUNCT: tok::PPToken = {
	"#" => <>,
	NON_HASH_PUNCT => <>,
};

NON_HASH_PUNCT: tok::PPToken = {
	"##" => <>,
	"(" => <>,
	")" => <>,
	"{" => <>,
	"}" => <>,
	"*" => <>,
	"=" => <>,
	";" => <>,
};


extern {
	type Location = usize;
	type Error = diag::Error;

	enum tok::PPToken {
		HEADER_NAME => tok::PPToken{kind: tok::PPTokenKind::HeaderName(_), ..},
		IDENT => tok::PPToken{kind: tok::PPTokenKind::Ident(_), ..},
		PP_NUMBER => tok::PPToken{kind: tok::PPTokenKind::PPNumber(_), ..},
		CHAR_CONST => tok::PPToken{kind: tok::PPTokenKind::CharConst(_), ..},
		STRING_LITERAL => tok::PPToken{kind: tok::PPTokenKind::StringLiteral(_), ..},
		"\n" => tok::PPToken{kind: tok::PPTokenKind::NewLine(_), ..},
		"#" => tok::PPToken{kind: tok::PPTokenKind::Punct(tok::Punct::Hash), ..},
		"##" => tok::PPToken{kind: tok::PPTokenKind::Punct(tok::Punct::HashHash), ..},
		"(" => tok::PPToken{kind: tok::PPTokenKind::Punct(tok::Punct::LParen), ..},
		")" => tok::PPToken{kind: tok::PPTokenKind::Punct(tok::Punct::RParen), ..},
		"{" => tok::PPToken{kind: tok::PPTokenKind::Punct(tok::Punct::LCurly), ..},
		"}" => tok::PPToken{kind: tok::PPTokenKind::Punct(tok::Punct::RCurly), ..},
		"*" => tok::PPToken{kind: tok::PPTokenKind::Punct(tok::Punct::Star), ..},
		"=" => tok::PPToken{kind: tok::PPTokenKind::Punct(tok::Punct::Equal), ..},
		";" => tok::PPToken{kind: tok::PPTokenKind::Punct(tok::Punct::SemiColon), ..},
	}
}
