use std::cell::RefCell;
use std::rc::Rc;
use std::io::{Read, BufReader};
use std::fs;
use std::path::PathBuf;

use crate::diag::lex as diag;
use lalrpop_util as lalr;
use crate::lex::PPTokenStack;
use crate::lex::lexer::Lexer;
use crate::tok::*;

grammar<'a>(
	file_map: &mut bimap::BiHashMap<usize, PathBuf>,
	stack_ref: &'a Rc<RefCell<PPTokenStack>>
);

pub Tokens: Vec<(usize, Token, usize)> = {
	GroupPart => <>,
	<mut group: Tokens> <mut part: GroupPart> => {
		group.append(&mut part);
		group
	},
}

GroupPart: Vec<(usize, Token, usize)> = {
	// IfSection => <>,
	ControlLine => <>,
	TextLine => <>,
	// "#" NonDirective => <>
};

ControlLine: Vec<(usize, Token, usize)> = {
	// TODO: make this fallible
	"#" Include <header:HEADER_NAME> "\n" => {
		let origin_path = file_map.get_by_left(&header.file_key).unwrap();
		let header_name = PathBuf::from(header.kind.to_name());
		let full_path = origin_path.parent().unwrap().join(header_name);
		let mut stack = stack_ref.borrow_mut();
		let mut file = fs::File::open(&full_path).unwrap();
		
		let mut reader = BufReader::new(file);
		let mut buf = String::new();
		reader.read_to_string(&mut buf).unwrap();

		let file_key = if let Some(file_key) = file_map.get_by_right(&full_path) {
			*file_key
		} else {
			let file_key = file_map.len();
			file_map.insert(file_key, full_path);
			file_key
		};

		stack.push_lexer(Lexer::new(buf, file_key));
		vec![]
	},
};

TextLine: Vec<(usize, Token, usize)> = {
	"\n" => vec![],
	<nh:NonHash> <mut tokens: PreprocessingToken*> "\n" => {
		let mut result = vec![nh];
		result.append(&mut tokens);
		result
	},
};

PreprocessingToken: (usize, Token, usize) = {
	HEADER_NAME => {
		todo!("header-name");
	},
	<lo:@L> <tk:IDENT> <hi:@R> => {
		let file_key = tk.file_key;
		(
			lo,
			Token{
				kind: tk.unwrap_ident().into(),
				file_key,
			},
			hi
		)
	},
	<lo:@L> <tk:PP_NUMBER> <hi:@R> => {
		let file_key = tk.file_key;
		let pp_num = tk.unwrap_pp_number();
		(
			lo,
			Token {
				kind: TokenKind::try_from(pp_num).unwrap(),
				file_key,
			},
			hi
		)
	},
	<lo:@L> <tk:CHAR_CONST> <hi:@R> => {
		let file_key = tk.file_key;
		(
			lo,
			Token {
				kind: TokenKind::Constant(Constant::CharConst(tk.unwrap_char_const())),
				file_key,
			},
			hi
		)
	},
	<lo:@L> <tk:STRING_LITERAL> <hi:@R> => {
		let file_key = tk.file_key;
		(
			lo,
			Token {
				kind: tk.unwrap_string_literal().into(),
				file_key,
			},
			hi
		)
	},
	<lo:@L> <tk:PUNCT> <hi:@R> => {
		let file_key = tk.file_key;
		(
			lo,
			Token {
				kind: TokenKind::Punct(tk.unwrap_punct()),
				file_key,
			},
			hi
		)
	}
};


Include: Ident = <lo:@L> <tk:IDENT> <hi:@R> =>? {
	if tk.unwrap_ident().0 == "include".to_string() {
		Ok(Ident("include".to_string()))
	} else {
		Err(lalr::ParseError::User {
			error: diag::Error{
				kind: diag::ErrorKind::InvalidToken,
				loc: (lo, hi)
			}
		})
	}
};

NonHash: (usize, Token, usize) = {
	<lo:@L> <tk:IDENT> <hi:@R> => {
		let file_key = tk.file_key;
		(
			lo,
			Token{
				kind: TokenKind::Ident(tk.unwrap_ident()),
				file_key,
			},
			hi
		)
	},
	<lo:@L> <tk:STRING_LITERAL> <hi:@R> => {
		let file_key = tk.file_key;
		(
			lo,
			Token {
				kind: TokenKind::StringLiteral(tk.unwrap_string_literal()),
				file_key,
			},
			hi
		)
	},
	<lo:@L> <tk:NON_HASH_PUNCT> <hi:@R> => {
		let file_key = tk.file_key;
		(
			lo,
			Token {
				kind: TokenKind::Punct(tk.unwrap_punct()),
				file_key,
			},
			hi
		)
	},
};

PUNCT: PPToken = {
	"#" => <>,
	NON_HASH_PUNCT => <>,
};

NON_HASH_PUNCT: PPToken = {
	"##" => <>,
	"(" => <>,
	" (" => <>,
	")" => <>,
	"{" => <>,
	"}" => <>,
	"*" => <>,
	"=" => <>,
	";" => <>,
};


extern {
	type Location = usize;
	type Error = diag::Error;

	enum PPToken {
		HEADER_NAME => PPToken{kind: PPTokenKind::HeaderName(_), ..},
		IDENT => PPToken{kind: PPTokenKind::Ident(_), ..},
		PP_NUMBER => PPToken{kind: PPTokenKind::PPNumber(_), ..},
		CHAR_CONST => PPToken{kind: PPTokenKind::CharConst(_), ..},
		STRING_LITERAL => PPToken{kind: PPTokenKind::StringLiteral(_), ..},
		"\n" => PPToken{kind: PPTokenKind::NewLine(_), ..},
		"#" => PPToken{kind: PPTokenKind::Punct(Punct::Hash), ..},
		"##" => PPToken{kind: PPTokenKind::Punct(Punct::HashHash), ..},
		"(" => PPToken{kind: PPTokenKind::Punct(Punct::LParen), leading_space: false, ..},
		" (" => PPToken{kind: PPTokenKind::Punct(Punct::LParen), leading_space: true, ..},
		")" => PPToken{kind: PPTokenKind::Punct(Punct::RParen), ..},
		"{" => PPToken{kind: PPTokenKind::Punct(Punct::LCurly), ..},
		"}" => PPToken{kind: PPTokenKind::Punct(Punct::RCurly), ..},
		"*" => PPToken{kind: PPTokenKind::Punct(Punct::Star), ..},
		"=" => PPToken{kind: PPTokenKind::Punct(Punct::Equal), ..},
		";" => PPToken{kind: PPTokenKind::Punct(Punct::SemiColon), ..},
	}
}
